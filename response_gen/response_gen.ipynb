{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "17uYVk-xxW3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a8a5d769-c868-4d3a-8ace-4b52b7c9bd6b"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input , Dense , GRU , LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-21 12:44:38--  http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz\n",
            "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
            "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/mono/en.txt.gz [following]\n",
            "--2020-06-21 12:44:38--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/mono/en.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3663376519 (3.4G) [application/gzip]\n",
            "Saving to: ‘download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz.1’\n",
            "\n",
            "download.php?f=Open 100%[===================>]   3.41G  23.3MB/s    in 2m 35s  \n",
            "\n",
            "2020-06-21 12:47:15 (22.5 MB/s) - ‘download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz.1’ saved [3663376519/3663376519]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e-cj4iQ4MeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3893a93c-f7f5-4c73-be0b-f29eb49a9380"
      },
      "source": [
        "!gunzip -k '/content/download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz'\n",
        "!mkdir lines\n",
        "\n",
        "!split -a 3 -l 100000 '/content/download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en' lines/lines-\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: /content/download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en already exists; do you wish to overwrite (y or n)? ^C\n",
            "mkdir: cannot create directory ‘lines’: File exists\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhdNKkDSymEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "f = open('/content/drive/My Drive/lines-abu.txt' ,'r')\n",
        "for i,line in enumerate(f):\n",
        "  if i%2==0:\n",
        "    x.append(line)\n",
        "  else:\n",
        "    y.append(line)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55ypOF1mCqEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6029cb3f-cf61-4491-91ef-3c7467d75f66"
      },
      "source": [
        "print(len(x))\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input , Dense , GRU , LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "num_samples = 40000\n",
        "\n",
        "\n",
        "max_encoder_seq_length = 15\n",
        "max_decoder_seq_length = 15\n",
        "\n",
        "\n",
        "print(len(y))\n",
        "\n",
        "print(x[:10])\n",
        "print(y[:10])\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_samples)\n",
        "tokenizer.fit_on_texts(x)\n",
        "sequences_1 = tokenizer.texts_to_sequences(x)\n",
        "\n",
        "word_index_1 = (tokenizer.word_index)\n",
        "num_encoder_tokens = len(word_index_1)\n",
        "print('Found %s unique tokens.' % len(word_index_1))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_samples)\n",
        "tokenizer.fit_on_texts(y)\n",
        "sequences_2 = tokenizer.texts_to_sequences(y)\n",
        "\n",
        "word_index_2 = tokenizer.word_index\n",
        "num_decoder_tokens = len(word_index_2)\n",
        "print('Found %s unique tokens.' % len(word_index_2))\n",
        "\n",
        "data_1 = pad_sequences(sequences_1, maxlen=max_encoder_seq_length , padding='post')\n",
        "data_2 = pad_sequences(sequences_2, maxlen=max_decoder_seq_length , padding= 'post')\n",
        "\n",
        "print(data_1.shape)\n",
        "print(data_2.shape)\n",
        "print(num_encoder_tokens)\n",
        "print(num_decoder_tokens)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250000\n",
            "['Presented by IM Pictures\\n', 'In association with MVP Venture Capital and Cinema Service\\n', 'My Sassy Girl\\n', \"We promised to meet here two years later, but she hasn't come yet.\\n\", 'Here we go.\\n', 'One, two...\\n', 'Hello?\\n', \"Sorry, I'm on my way.\\n\", \"Yes, I'm coming.\\n\", 'Bye.\\n']\n",
            "['Produced by Shin Cine\\n', 'Jeon Ji-hyun Cha Tae-hyun\\n', 'Exactly two years ago today, she and I buried a time capsule here.\\n', \"I'm going to wait.\\n\", \"Please, don't move.\\n\", 'Wait a minute.\\n', 'Oh, auntie.\\n', \"I'm really sorry.\\n\", \"I'm having my photo taken.\\n\", 'Are you ready?\\n']\n",
            "Found 24584 unique tokens.\n",
            "Found 24569 unique tokens.\n",
            "(250000, 15)\n",
            "(250000, 15)\n",
            "24584\n",
            "24569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9ZdvGxgYsx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2fd3b35c-2850-4263-f813-17fff26515b4"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input , Dense , GRU , LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "embedding_dim = 50\n",
        "Tx = max_encoder_seq_length\n",
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation('softmax', name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
        "dotor = Dot(axes = 1)\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('/content/drive/My Drive/glove.6B/', 'glove.6B.50d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index_1) + 1, embedding_dim))\n",
        "for word, i in word_index_1.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(embedding_matrix.shape)\n",
        "x = Embedding(len(word_index_1)+1 ,embedding_dim,weights=[embedding_matrix],input_length=max_encoder_seq_length,trainable=False)\n",
        "\n",
        "def one_step_attention(a, s_prev):\n",
        "    \"\"\"\n",
        "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
        "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
        "    \n",
        "    Arguments:\n",
        "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
        "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
        "    \n",
        "    Returns:\n",
        "    context -- context vector, input of the next (post-attention) LSTM cell\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
        "    s_prev = repeator(s_prev)\n",
        "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
        "    # For grading purposes, please list 'a' first and 's_prev' second, in this order.\n",
        "    concat = concatenator(inputs =([a,s_prev]))\n",
        "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
        "    e = densor1(concat)\n",
        "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
        "    energies = densor2(e)\n",
        "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
        "    alphas = activator(energies)\n",
        "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
        "    context = dotor([alphas,a])\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return context\n",
        "\n",
        "\n",
        "post_activation_LSTM_cell = LSTM(128, return_state = True) # post-attention LSTM \n",
        "output_layer = Dense(24570, activation='softmax')\n",
        "\n",
        "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "\n",
        "    \n",
        "    # Define the inputs of your model with a shape (Tx,)\n",
        "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
        "    # for the decoder LSTM with shape (n_s,)\n",
        "    X = Input(shape=(Tx,))\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Step 1: Define your pre-attention Bi-LSTM. (≈ 1 line)\n",
        "    e = x(X)\n",
        "    a = Bidirectional(LSTM(units = n_a ,return_sequences = True))(e)\n",
        "    \n",
        "    # Step 2: Iterate for Ty steps\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
        "        context = one_step_attention(a, s)\n",
        "        \n",
        "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
        "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
        "        s, _, c = post_activation_LSTM_cell(inputs = context,initial_state = [s,c])\n",
        "        \n",
        "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
        "        outputs.append(out)\n",
        "    \n",
        "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
        "    model = Model(inputs = [X,s0,c0],outputs = outputs)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = model(15 , 15 , 128, 128, 24584, 24569)\n",
        "\n",
        "opt = Adam(lr = 0.005, beta_1 = 0.9,beta_2 = 0.999 , decay = 0.01)\n",
        "model.compile(optimizer = opt , loss = \"sparse_categorical_crossentropy\" ,metrics = ['accuracy'])\n",
        "\n",
        "s0 = np.zeros((250000, 128))\n",
        "c0 = np.zeros((250000, 128))\n",
        "\n",
        "data_2 = list(data_2.swapaxes(0,1))\n",
        "model.fit([data_1, s0, c0], data_2, epochs=1, batch_size=10000)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "(24585, 50)\n",
            "Epoch 1/1\n",
            "250000/250000 [==============================] - 2999s 12ms/step - loss: 78.2885 - dense_3_loss: 3.7666 - dense_3_accuracy: 0.0010 - dense_3_accuracy_1: 0.0993 - dense_3_accuracy_2: 0.2207 - dense_3_accuracy_3: 0.3448 - dense_3_accuracy_4: 0.4637 - dense_3_accuracy_5: 0.5702 - dense_3_accuracy_6: 0.6570 - dense_3_accuracy_7: 0.7246 - dense_3_accuracy_8: 0.7780 - dense_3_accuracy_9: 0.8156 - dense_3_accuracy_10: 0.8469 - dense_3_accuracy_11: 0.8714 - dense_3_accuracy_12: 0.8904 - dense_3_accuracy_13: 0.9050 - dense_3_accuracy_14: 0.9170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f835a2a6780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuTr7qcg9x8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puxt3poKIenO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8zExdXPIgpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pwhbmhNLrto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfCfLIf1qYPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkkhF6LZsJ3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRJcQcW3sYha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}